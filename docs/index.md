# Why Local Learning?

Some of us (many of us) are trying
to learn insights from tiny amounts of  local data.
Not everyone has the resources to build models with one trillion+ parameters. 
And when the locals  use those larger
models, they need some reference model to test and assess the value-added (if any) of the general model.

The good news with local learning is that since the data points are few, so too can we make the learning
fast (since there is less data to process) and the AI simpler and more explainable (since there is less to do and explain).

TO demonstrate this,
this site is organized around a set of hand-on coding tutorials. All the code is written in Lua
(cause that is such a simple language) and, using any number of LLM tools, you can  translate  that code to anything else you want (\*).

- Setting up
  - [Editing and Debugging](dev.md)
  - [Coding experiments](Code.md)
- [Developing Code, 101](dev.md)
- [Numbers and Symbols](Numsym.md)
- Theory
  - [Algorithms](algos.md)


(\*) Of course that translation will not be perfect, but in the process of debugging the broken code you will
learn so much that is useful.
