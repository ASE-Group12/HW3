<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Tim Menzies" />
  <meta name="dcterms.date" content="2024-03-22" />
  <title>Intro SE 4 AI</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
  </style>
  <link rel="stylesheet" href="ezr.css" />
  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js"
  type="text/javascript"></script>
</head>
<body>
<a href="https://github.com/timm/ezr"> <img
alt="Home" src="https://img.shields.io/badge/home-black"></a> <a href="https://raw.githubusercontent.com/timm/ezr/main/ezr.py"> <img
alt="Download" src="https://img.shields.io/badge/download-gold"></a> <a 
href="https://github.com/timm/ezr/issues"> <img
alt="Issues" src="https://img.shields.io/badge/issues-red"></a> <a 
href="https://github.com/timm/ezr/blob/main/LICENSE.md"> <img
alt="License" src="https://img.shields.io/badge/license-bsd2-green"></a> <img 
src="https://img.shields.io/badge/purpose-ai%20,%20se-blueviolet"> <img
alt="Purpose" src="https://img.shields.io/badge/language-python3-blue">

<p><em>20-40 samples can find significant improvements in 10,000+ examples. Wanna know how?</em><hr>
<header id="title-block-header">
<h1 class="title">Intro SE 4 AI</h1>
<p class="author">Tim Menzies</p>
<p class="date">March 22, 2024</p>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#am-i-or-you-a-good-engineer"
id="toc-am-i-or-you-a-good-engineer"><span
class="toc-section-number">1</span> Am I (or you) a good
engineer?</a></li>
<li><a href="#can-we-engineering-an-ai-system-simply-quickly"
id="toc-can-we-engineering-an-ai-system-simply-quickly"><span
class="toc-section-number">2</span> Can we engineering an AI system?
Simply? Quickly?</a></li>
<li><a href="#which-raises-the-question."
id="toc-which-raises-the-question."><span
class="toc-section-number">3</span> Which raises the question….</a></li>
<li><a href="#why-study-simplicity" id="toc-why-study-simplicity"><span
class="toc-section-number">4</span> Why study simplicity?</a></li>
<li><a href="#why-study-simplicity-2"
id="toc-why-study-simplicity-2"><span
class="toc-section-number">5</span> Why study simplicity? (2)</a></li>
<li><a href="#surfing-the-long-tail"
id="toc-surfing-the-long-tail"><span class="toc-section-number">6</span>
Surfing the long tail</a></li>
<li><a href="#aside-q-what-is-software-engineering"
id="toc-aside-q-what-is-software-engineering"><span
class="toc-section-number">7</span> Aside: Q: What is Software
Engineering?</a></li>
<li><a href="#application-of-little-data-in-se-software-review"
id="toc-application-of-little-data-in-se-software-review"><span
class="toc-section-number">8</span> Application of Little Data in SE:
Software Review</a></li>
<li><a href="#more-on-software-review"
id="toc-more-on-software-review"><span
class="toc-section-number">9</span> More on Software Review</a></li>
<li><a href="#what-isnt-softwar-revie1"
id="toc-what-isnt-softwar-revie1"><span
class="toc-section-number">10</span> What Isn’t Softwar Revie1</a></li>
<li><a href="#q-how-few-questions-can-humans-answer"
id="toc-q-how-few-questions-can-humans-answer"><span
class="toc-section-number">11</span> Q: How few questions can humans
answer?</a></li>
<li><a href="#tricks-often-cheaper-faster-to-find-x-than-y"
id="toc-tricks-often-cheaper-faster-to-find-x-than-y"><span
class="toc-section-number">12</span> Tricks: Often cheaper, faster, to
find “X” than “Y”</a></li>
<li><a href="#se-examples-where-finding-x-is-cheaper-than-y"
id="toc-se-examples-where-finding-x-is-cheaper-than-y"><span
class="toc-section-number">13</span> SE Examples where finding <span
class="math inline">\(X\)</span> is cheaper than <span
class="math inline">\(Y\)</span></a></li>
<li><a href="#this-is-called-active-learning"
id="toc-this-is-called-active-learning"><span
class="toc-section-number">14</span> This is called “Active
Learning”</a></li>
<li><a href="#an-active-learning-loop"
id="toc-an-active-learning-loop"><span
class="toc-section-number">15</span> An Active Learning Loop</a></li>
<li><a href="#three-kinds-of-active-learning"
id="toc-three-kinds-of-active-learning"><span
class="toc-section-number">16</span> Three kinds of active
learning</a></li>
</ul>
</nav>
<h2 data-number="1" id="am-i-or-you-a-good-engineer"><span
class="header-section-number">1</span> Am I (or you) a good
engineer?</h2>
<p>If you have been doing something for a while then can you or I:</p>
<ul>
<li>Do it simpler, faster. using fewer resources?</li>
<li>Know how to combine things, such that you can more with less?</li>
<li>Teach seemingly complex things to newbies?</li>
</ul>
<h2 data-number="2"
id="can-we-engineering-an-ai-system-simply-quickly"><span
class="header-section-number">2</span> Can we engineering an AI system?
Simply? Quickly?</h2>
<p>Here we explore dozens of SE problems <a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>
using explainable AI for semi-supervised multi-objective
optimization.</p>
<ul>
<li>Internally, this is coded via sequential model optimization and
membership query synthesis.</li>
</ul>
<p>Sounds complex, right?</p>
<ul>
<li>But it ain’t.</li>
<li>In fact, as I hope to show, all the above is just a hundred lines of
code (caveat: if you are using the right underlying object model).</li>
</ul>
<h2 data-number="3" id="which-raises-the-question."><span
class="header-section-number">3</span> Which raises the question….</h2>
<p>What else is similarly simple?</p>
<ul>
<li>How many of our complex problems … aren’t?</li>
</ul>
<p>My challenge to you is this:</p>
<ul>
<li>Please go and find out.</li>
<li>Take a working system, see what you can throw away (while the
remaining system is still useful and fast).</li>
<li>Let me know happens so I can add your fantastic new, and simple,
idea to this code</li>
</ul>
<h2 data-number="4" id="why-study-simplicity"><span
class="header-section-number">4</span> Why study simplicity?</h2>
<ul>
<li>Cause we are getting really really good at reasoning with very
little data</li>
<li>Cause its good science
<ul>
<li>If you really understand “it”, can you do “it” again, very very
simply</li>
</ul></li>
<li>Cause the world is changing
<ul>
<li>Next generation of satellite internet providers</li>
<li>Connecting millions of new programmers willing to work for <span
class="math inline">\(\frac{1}{20}\)</span>th of the salary you
want</li>
<li>In that world, you do not want to be the programmer</li>
<li>You want to be the optimizer who controls and improves the work of
others.</li>
</ul></li>
<li>Cause almost no one else is studying reasoning with very little
data</li>
</ul>
<h2 data-number="5" id="why-study-simplicity-2"><span
class="header-section-number">5</span> Why study simplicity? (2)</h2>
<ul>
<li>Cause everyone has gone mad on complexity.
<ul>
<li>A small number of very large companies have built empires based on
“big data”</li>
<li>Five years ago, no on one wanted to head about simplicity</li>
<li>But after three years of constant tech lay offs, and increasing
challenges for getting jobs at these large organizations …</li>
<li>… my students now know they need to graduate with knowledge about
“big data” AND alternate approaches.</li>
</ul></li>
<li>Cause big data is running out of data (see next slide).</li>
</ul>
<h2 data-number="6" id="surfing-the-long-tail"><span
class="header-section-number">6</span> Surfing the long tail</h2>
<ul>
<li>LLMs? For everything?
<ul>
<li>LLMs know a lot, about things we do a lot (e.g. “if” statements in
code)</li>
<li>And they know <em>less</em> about things we do <em>less</em>
often</li>
</ul></li>
<li>Model collapse:
<ul>
<li>We are about to run out of training data <a href="#fn2"
class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> for
LLMs.</li>
<li>Can’t reply of synthetic data generation (no new information from
data already seen)</li>
</ul></li>
<li>So, we make do with <em>less</em> data?
<ul>
<li>Are their domain, were models need less, not more, data?</li>
</ul></li>
</ul>
<h2 data-number="7" id="aside-q-what-is-software-engineering"><span
class="header-section-number">7</span> Aside: Q: What is Software
Engineering?</h2>
<ul>
<li>A: The delivery and maintainable of software products to an
acceptable standard, built using current constraints.</li>
<li>LLMs build “quality” solutions? That respect “current
constraints”?</li>
<li>Do LLMs work for all tasks?
<ul>
<li>Not really<a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>. They often produce useful
suggestions. But mixed in with the good is also the bad, the terrible,
the misleading and the dangerous<a href="#fn4" class="footnote-ref"
id="fnref4" role="doc-noteref"><sup>4</sup></a>.</li>
</ul></li>
<li>Are LLMs bad science?
<ul>
<li>Harder for research LLM papers to, say, run 20 times and report the
variability in the results</li>
<li>Harder for other researchers to check results from other
people.</li>
<li>AI needs 1% of world’s power, creating 4% of our carbon emissions<a
href="#fn5" class="footnote-ref" id="fnref5"
role="doc-noteref"><sup>5</sup></a></li>
</ul></li>
<li>Do they need too much data ? (above)</li>
<li>Are there other options? That use less data? That can be
tested?</li>
</ul>
<h2 data-number="8"
id="application-of-little-data-in-se-software-review"><span
class="header-section-number">8</span> Application of Little Data in SE:
Software Review</h2>
<p><img src="./img/review.png" width="300" /></p>
<ul>
<li>The more we use AI in SE, the more code will be auto-generated.</li>
<li>The more we auto-generate code
<ul>
<li>the less time software engineers spend writing and reviewing new
code, written by someone or something else (which internally, are a
mystery)</li>
</ul></li>
<li>The less we understand code,
<ul>
<li>the more we will use black-boxes components, where, once a system is
assembled, its control settings are tuned.</li>
</ul></li>
</ul>
<p>In this scenario: we must reduce the effort (human and CPU) for that
tuning.</p>
<h2 data-number="9" id="more-on-software-review"><span
class="header-section-number">9</span> More on Software Review</h2>
<ul>
<li>We define “software review” as a panel of SMEs (subject matter
experts), looking at examples of behavior to recommend how to improve
software.</li>
<li>SME time is usually very limited so, such reviews must complete
after looking at just a small number of very informative examples.</li>
<li>To support the software review process, we explore methods that
train a predictive model to guess if some oracle will like/dislike the
next example.</li>
<li>These predictive models work with SMEs to guide them as they explore
the examples. Afterwards, the models can handle new examples, while the
panelists are busy, elsewhere</li>
</ul>
<h2 data-number="10" id="what-isnt-softwar-revie1"><span
class="header-section-number">10</span> What Isn’t Softwar Revie1</h2>
<p>(Aside: Origninally, I called in “peeking” but that didn’t sound very
cool.)</p>
<h2 data-number="11" id="q-how-few-questions-can-humans-answer"><span
class="header-section-number">11</span> Q: How few questions can humans
answer?</h2>
<p>A: Not so many</p>
<table>
<colgroup>
<col style="width: 38%" />
<col style="width: 61%" />
</colgroup>
<thead>
<tr>
<th style="text-align: left;">What</th>
<th style="text-align: left;">N</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: left;">Standard theory</td>
<td style="text-align: left;">more is always better</td>
</tr>
<tr>
<td style="text-align: left;">Cognitive Science</td>
<td style="text-align: left;">7 plus or minus 2</td>
</tr>
<tr>
<td style="text-align: left;">From human studies (cost estimation, rep
grids)<a href="#fn6" class="footnote-ref" id="fnref6"
role="doc-noteref"><sup>6</sup></a></td>
<td style="text-align: left;">10 to 20 examples per 1-4 hours</td>
</tr>
<tr>
<td style="text-align: left;">Regression <a href="#fn7"
class="footnote-ref" id="fnref7"
role="doc-noteref"><sup>7</sup></a></td>
<td style="text-align: left;">10-20 examples per attribute</td>
</tr>
<tr>
<td style="text-align: left;">Semi-supervised learning</td>
<td style="text-align: left;"><span
class="math inline">\(\sqrt{N}\)</span></td>
</tr>
<tr>
<td style="text-align: left;">Zhu et al.<a href="#fn8"
class="footnote-ref" id="fnref8"
role="doc-noteref"><sup>8</sup></a></td>
<td style="text-align: left;">100 images</td>
</tr>
<tr>
<td style="text-align: left;">Menzies et al. 2008<a href="#fn9"
class="footnote-ref" id="fnref9"
role="doc-noteref"><sup>9</sup></a></td>
<td style="text-align: left;">50 examples</td>
</tr>
<tr>
<td style="text-align: left;">Chessboard model<a href="#fn10"
class="footnote-ref" id="fnref10"
role="doc-noteref"><sup>10</sup></a></td>
<td style="text-align: left;">200 examples</td>
</tr>
<tr>
<td style="text-align: left;">Probable Correctness theory<a href="#fn11"
class="footnote-ref" id="fnref11"
role="doc-noteref"><sup>11</sup></a></td>
<td style="text-align: left;">simpler cases: 50 to 6 (if binary
chop)</td>
</tr>
<tr>
<td style="text-align: left;"></td>
<td style="text-align: left;">safety-critical cases: 272 to 8 (if binary
chop)</td>
</tr>
</tbody>
</table>
<h2 data-number="12"
id="tricks-often-cheaper-faster-to-find-x-than-y"><span
class="header-section-number">12</span> Tricks: Often cheaper, faster,
to find “X” than “Y”</h2>
<ul>
<li><span class="math inline">\(Y=f(X)\)</span>
<ul>
<li><span class="math inline">\(X\)</span>,<span
class="math inline">\(Y\)</span> are our independent and dependent
variables.</li>
<li><span class="math inline">\(f\)</span> is the thing we are trying to
find</li>
</ul></li>
<li>e.g. Fishing:
<ul>
<li>Glance up and down the river.</li>
<li>That looks like a good spot.</li>
<li>3 hours later: well, it was not</li>
</ul></li>
<li>e.g. Used car yard:
<ul>
<li>Glancing over 100 cars: count the cars and their colors and number
of wheels and size of car.</li>
<li>But to find gas mileage– got to take each out for a long drive.</li>
</ul></li>
</ul>
<h2 data-number="13"
id="se-examples-where-finding-x-is-cheaper-than-y"><span
class="header-section-number">13</span> SE Examples where finding <span
class="math inline">\(X\)</span> is cheaper than <span
class="math inline">\(Y\)</span></h2>
<ul>
<li><span class="math inline">\(X\)</span>,<span
class="math inline">\(Y\)</span> are our independent and dependent
variables.</li>
<li>Quick to mine <span class="math inline">\(X\)</span> GitHub to get
code size, dependencies per function,
<ul>
<li>Slow to get <span class="math inline">\(Y\)</span> (a) development
time, (b) what people will pay for it</li>
</ul></li>
<li>Quick to count <span class="math inline">\(X\)</span> the number of
classes in a system.
<ul>
<li>Slow to get <span class="math inline">\(Y\)</span> an organization
to tell you human effort to build and maintain that code.</li>
</ul></li>
<li>Quick to enumerate <span class="math inline">\(X\)</span> many
design options (20 yes-no = <span class="math inline">\(2^{20}\)</span>
options)
<ul>
<li>Slow to check <span class="math inline">\(Y\)</span> those options
with the human stakeholders.</li>
</ul></li>
<li>Quick to list <span class="math inline">\(X\)</span> configuration
parameters for the software.
<ul>
<li>Slow to find <span class="math inline">\(X\)</span> runtime and
energy requirements for all configurations.</li>
</ul></li>
<li>Quick to list <span class="math inline">\(X\)</span> data miner
params (e.g. how many neighbors in knn?)
<ul>
<li>Slow to find <span class="math inline">\(Y\)</span> best setting for
local data.</li>
</ul></li>
<li>Quick to make <span class="math inline">\(X\)</span> test case
inputs using (e.g.) random input selection
<ul>
<li>Slow to run all tests and get <span class="math inline">\(Y\)</span>
humans to check each output</li>
</ul></li>
</ul>
<h2 data-number="14" id="this-is-called-active-learning"><span
class="header-section-number">14</span> This is called “Active
Learning”</h2>
<ul>
<li>Learning works better if the learner can pick its training
data[^brochu]. Given two models that predict for good <span
class="math inline">\(g\)</span> or bad <span
class="math inline">\(b\)</span>:</li>
<li>An active learning loop:</li>
</ul>
<h2 data-number="15" id="an-active-learning-loop"><span
class="header-section-number">15</span> An Active Learning Loop</h2>
<ul>
<li><em>Labelling</em>: given an example with <span
class="math inline">\(X\)</span>, but not <span
class="math inline">\(Y\)</span>, get the <span
class="math inline">\(Y\)</span>.</li>
<li>Just for simplicity, assume we a model can inputs <span
class="math inline">\(X\)</span> values to predict for good <span
class="math inline">\(g\)</span> or bad <span
class="math inline">\(b\)</span>:</li>
</ul>
<table>
<colgroup>
<col style="width: 15%" />
<col style="width: 38%" />
<col style="width: 46%" />
</colgroup>
<thead>
<tr>
<th style="text-align: right;">n</th>
<th>Task</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: right;">1</td>
<td>Sample a little</td>
<td>Get a get a few <span class="math inline">\(Y\)</span> values
(picked at random?)</td>
</tr>
<tr>
<td style="text-align: right;">2</td>
<td>Learn a little</td>
<td>Build a tiny model from that sample</td>
</tr>
<tr>
<td style="text-align: right;">3</td>
<td>Reflect</td>
<td>Compute <span class="math inline">\(b,r\)</span></td>
</tr>
<tr>
<td style="text-align: right;">4</td>
<td>Acquire</td>
<td>Label an example that (e.g.) maximizes <span
class="math inline">\(b/r\)</span>. Add it to the sample</td>
</tr>
<tr>
<td style="text-align: right;">5</td>
<td>Repeat</td>
<td>Goto 2</td>
</tr>
</tbody>
</table>
<p>How to - Sample, once - Use reflection to find one unlabelled
thingFind &amp;$ the <span class="math inline">\(X\)</span> variables, -
guess what might be the next most informative example - get its <span
class="math inline">\(Y\)</span> value, .</p>
<h2 data-number="16" id="three-kinds-of-active-learning"><span
class="header-section-number">16</span> Three kinds of active
learning</h2>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p><a
href="https://github.com/timm/ezr/tree/main/data">github.com/timm/ezr/tree/main/data</a><a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Udandarao, V., Prabhu, A., Ghosh, A., Sharma, Y., Torr,
P.H., Bibi, A., Albanie, S. and Bethge, M., 2024. No” zero-shot” without
exponential data: Pretraining concept frequency determines multimodal
model performance. arXiv preprint arXiv:2404.04125.<a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p><a
href="https://docs.google.com/document/d/1dF4GePCf04IW5uZnRSGQXRlzo5VyD5u0PQ3hfy-Zd6Q/edit">docs.google.com/document/d/1dF4GePCf04IW5uZnRSGQXRlzo5VyD5u0PQ3hfy-Zd6Q/edit</a>.<a
href="#fnref3" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p><a
href="https://docs.google.com/document/d/1dF4GePCf04IW5uZnRSGQXRlzo5VyD5u0PQ3hfy-Zd6Q/edit">docs.google.com/document/d/1dF4GePCf04IW5uZnRSGQXRlzo5VyD5u0PQ3hfy-Zd6Q/edit</a>.<a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p><a
href="https://www.linkedin.com/pulse/data-centers-its-environmental-impacts-i%C5%9F%C4%B1l-durmu%C5%9F-q5xvf/">www.linkedin.com/pulse/data-centers-its-environmental-impacts-i%C5%9F%C4%B1l-durmu%C5%9F-q5xvf/</a><a
href="#fnref5" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn6"><p>M. Easterby-Smith, Design, analysis and interpretation
of repertory grids, International Journal of Man-Machine Studies, 13(1),
1980, 3-24,<a href="#fnref6" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li
id="fn7"><p>www.quora.com/How-many-data-points-are-enough-for-linear-regression<a
href="#fnref7" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn8"><p>Zhu, X., Vondrick, C., Fowlkes, C.C. et al. Do We Need
More Training Data?. Int J Comput Vis 119, 76–92 (2016).
https://doi-org.prox.lib.ncsu.edu/10.1007/s11263-015-0812-2<a
href="#fnref8" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn9"><p>Menzies, T., Turhan, B., Bener, A., Gay, G., Cukic, B.,
PROMISE workshop, 2008, (pp. 47-54).<a href="#fnref9"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn10"><p>J. Nam, W. Fu, S. Kim, T. Menzies and L. Tan,
“Heterogeneous Defect Prediction,” in IEEE Transactions on Software
Engineering, vol. 44, no. 9, pp. 874-896, 1 Sept. 2018, doi:<a
href="#fnref10" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn11"><p>My personnel reading of Richard G. Hamlet. 1987.
Probable correctness theory. Inf. Process. Lett. 25, 1 (20 April 1987),
17–25. https://doi.org/10.1016/0020-0190(87)90088-3<a href="#fnref11"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
</body>
</html>
